%% ==============================
\chapter{\iflanguage{ngerman}{Ausblick}{Conclusion}}
\label{sec:conclusion}
%% ==============================



Die Implementierung eines Clusteringbasierten Verfahren kam in dieser Arbeit zu einem Erfolg, jedoch gibt es noch sehr viele Verbesserungs- und Erweiterungsmöglichkeiten. Diese werden im folgenden Kapitel vorgestellt.
\newline
Die Visualisierung des Ventrikelsystems funktionierte bei nur wenigen Datensätzen. Bei den Restlichen wurde das System aus verschiedenen Gründen nicht erkannt. Es gab Probleme, wenn einerseits das Ventrikelsystem zu klein oder verformt war, oder andererseits die Hirnmasse im Kopf und um den Ventrikel herum andere Intensitätswerte als üblich hatten. Bei normalen Ventrikel funktionierte es teilweise auch nicht. Diese hohe Inkonsistenz gilt es zu beheben. Dazu können verschiedene Veränderungen vorgenommen werden.
\newline
Da das Verfahren oft daran scheiterte, die Kanten von Ventrikeln zu erkennen, da sie zu klein oder der Unterschied zur Umgebung zu gering ist, wäre es eine Möglichkeit, ein noch genaueres Clustern über dem LH-Raum zu implementieren. Dadurch würden jedoch noch mehr Cluster entstehen, was die Benutzung noch schwieriger macht. Dies könnte jedoch behoben werden, indem Cluster die am Rande des Volumens liegen weggelassen werden. Da das Ventrikelsystem in der Mitte des Kopfes liegt, ist es klar, dass diese Cluster keine Teile eines Ventrikels enthalten können. Weiterhin könnte ...
\todo{weiterschreiben}
\newline
Ein weiteres Problem war die Benutzerfreundlichkeit. Ein Anwender muss einen genauen Ablauf befolgen um zu einem Ergebnis zu kommen, indem er erst mithilfe der Konsole Daten laden, falls sie noch im .nrrd Format vorliegen formatieren, die Cluster erstellen lassen, diese in Unity laden, die passenden Cluster manuell herausfinden, und schließlich mit einem weiteren Befehl über die Kommandozeile zu einem Ergebnis verschmelzen lassen. Dieser Ablauf ist wenig Intuitiv und kann wie die Nutzerstudie aus Kapitel 6 gezeigt hat für Menschen ohne Programmiererfahrung zu einer Hürde werden.
\newline
Dies könnte an vielen Stellen verbessert werden. Die zwei Programme könnten zu einem verschmolzen werden, sodass der Benutzer direkt in Unity das Volumen laden und die IDs berechnen lassen könnte. Des Weiteren wäre es dann möglich, dass die Cluster direkt in Unity angezeigt, ausgewählt und verschmolzen werden könnten. Dadurch bestünde auch die Möglichkeit leicht zwischen der Cluster und der finalen Ansicht hin und her zu wechseln. Der Anwender muss sich dadurch nicht mehr mit Dateipfaden dem Speichern und Einlesen von Dateien im richtigen Format beschäftigen. Weiterhin könnte Nutzung durch das Erstellen einer GUI Intuitiver gemacht werden, damit keine Eingabe von Befehlen in eine Kommandozeile mehr nötig ist.
\newline
Ein Problem, dass auch vom Arzt erkannt wurde, ist die nicht glatte Darstellung im Ergebnis, sowie die vielen existierenden Ausreißer. Dies macht die Visualisierung ungenau und teilweise missverständlich.
\newline
Dies lies sich lösen, indem auf das Endergebnis weiter Algorithmen angewendet werden. Beispielsweise könnten mit Dilatations- und Erosionsfiltern die Oberfläche geschlossen und kleine Ausreißer eliminiert werden. Eine weitere Verbesserung hierbei wäre, einen Regiongrowingalgorithmus am Ende des Verfahrens anzuwenden. Dieser könnte das Ergebnis deutlich verbessern, da dadurch ein vollständigeres Bild des Ventrikelsystems entstehen und eventuell sogar weitere Ventrikel, wie zum Beispiel das Dritte und Vierte, erkannt werden könnten.
\newline
Weiterhin könnte an vermutlich mehreren Stellen des aktuellen Codes kleine Optimierungen vorgenommen werden, wie das Beispiel im Kapitel \nameref{sec:implementation}. Diese haben eine kleinen Auswirkung auf das Ergebnis könnte aber nützlich sein, um ein optimales Ergebnis zu erreichen.
\newline
Eine andere Stelle an der die Implementierung weiterentwickelt werden könnte, ist die Anwendung des Verfahrens auf große Volumen. Hierzu müsste einerseits, der Fehler behoben werden, dass die Berechnung für zu große Datensätze nicht funktioniert. Des Weiteren wäre dafür Nötig und von allgemeinem Vorteil, wenn die Berechnungszeit verbessert werden würde. Aktuell wird die komplette Berechnung parallel auf dem CPU laufen gelassen. Die Kalkulation der Cluster könnte jedoch auf der GPU stattfinden und damit schneller berechnet werden.

