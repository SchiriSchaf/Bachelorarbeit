%% ==============================
\chapter{\iflanguage{ngerman}{Stand der Wissenschenschaft und Technik}{State of the art}}
\label{sec:state_of_the_art}
%% ==============================




%%Bajaj Countour: \cite{bajaj1997contour} -1d


Das Gebiet der Transferfunktionen ist bereits weit erforscht und es existieren viele unterschiedliche Methoden und Herangehensweisen um medizinische Daten abhängig von verschiedenen Problemstellungen passend darzustellen.
\newline
Dabei kann ist einerseits zwischen dem Level an Automation eines Systems unterscheiden. Hierbei gibt es vollautomatische Verfahren, bei denen keine Interaktion mit den Benutzer von Nöten ist, semiautomatische Verfahren bei denen der Benutzer noch an gewissen Stellschrauben drehen kann um das Ergebnis zu beeinflussen und manuelle Verfahren, bei denen der Anwender das meiste selber machen muss.
\newline
Transferfunktionen unterscheiden sich weiterhin in ihrer Dimensionalität. Es gibt ein- zwei- und allgemein -mehrdimensionale Transferfunktionen. Des Weiteren sind die Grundlagen auf denen die Berechnungen ruhen teils völlig verschieden. Manche Verfahren basieren auf den Intensitätswerten oder deren Änderung im gegebenen Volumen. Andere basieren auf der Größe der Features die für den Nutzer von Interesse sind. Wieder andere sind Bildbasiert oder wenden Machinelearning an um zum gewünschten Ziel zu gelangen.
\newline
In diesem Abschnitt wird ein Überblick über die unterschiedlichen Vorgehensweisen von Transferfunktionen gegeben. Dabei werden diese im Folgenden in die Kategorien Eindimensionale, Zweidimensionale, Räumlichbasierte,Machinelearning, Bildbasierte und Clusteringbasierte Verfahren geteilt.
\newline
Dabei ist jedoch zu beachten, dass die Kategorien lediglich einer übersichtlichen Struktur dieses Abschnitts dienen. Die Kategorien hätten anders gewählt werden können. Des Weiteren können manche Verfahren nicht eindeutig in die hier genannte Unterteilung eingeteilt werden, da eine Mehrfachnennung möglich wäre.



\subsection{Eindimensionale Verfahren}

Die einfachste Form der Transferfunktionen, sind die eindimensionalen Transferfunktionen. In diesen, wird nur der Intensitätswert der Voxel in Betracht gezogen. Abgesehen von den niedrigen Berechnungszeiten, sind diese jedoch aus mehreren Gründen suboptimal. Medizinischen Daten werden gemessen und haben deshalb meist ein Rauschen, was die genaue Darstellung erschwert. Weiterhin sind die Intensitätswerte verschiedener Bereiche nah beieinander oder gar gleich und damit sind eindimensionale Transferfunktionen unpraktisch um verschiedene Materialien kenntlich zu machen. Trotzdem sind eindimensionale Transferfunktionen weit verbreitet und werden oft benutzt. 



\subsection{Zweidimensionale Verfahren}

\cite{kniss2002multidimensional} SG-TF


Die Arbeit von Shouren Lan \cite{lan2017improving} befasst sich mit der Verbesserung von 2D Transferfunktionen die auf Skalarwerten und Gradienten(SG-TF) basieren. Genauer geht es darum Überlappungen von Bereichen die nicht zusammen gehören zu vermeiden.
\newline
Dabei wird im Paper zwischen 3 verschiedenen Klassen von Strukturen unterschieden:
\begin{itemize}
\item (i) Strukturen die keine andere Struktur berühren
\item (ii) Strukturen die keine andere Struktur berühren, jedoch nah an einer andern liegen
\item (iii) Strukturen die andere Strukturen berühren
\end{itemize} 
Wenn der Benutzer eine Region ausgewählt hat, werden zunächst alle Strukturen in dem Bereich klassifiziert und kleine Fragmente entfernt. Durch verschiedene Algorithmen werden Strukturen der Klassen (ii) durch Erosion, Dilatation, Aufteilen und neu zusammenfügen von einander getrennt. Strukturen der Klasse (iii) werden durch eine weitere niedrig dimensionale Transferfunktion getrennt. Anschließend werden Löcher, die bei dem Aufteilen der beiden Strukturen entstehen mithilfe von einem Dilatationsoperator geschlossen. Als letztes wird den unterschiedlichen Strukturen verschiedene Farben und Intensitäten zugewiesen.
\newline
Das Vorgehen von Lan führt zwar zu guten Ergebnissen und wurde sogar schon am Ventrikelsystem getestet. Jedoch wäre die Implementierung der Unterscheidung der Klassen und die verschiedenen Algorithmen zum Teilen, schließen von Löchern etc. zu Zeitaufwändig für den Rahmen dieser Bachelorarbeit.



\subsection{Räumlichbasierte Verfahren}

In der Arbeit von Wesarg und Kirschner \cite{wesarg2009structure, wesarg20102d} wird das \textit{Stucture-Size-Enhanced Histogram} vorgestellt.
\newline
Zur Berechnung des Histogramms  muss für jeden Voxel die Strukturgröße abgeschätzt werden. Dies geschieht, indem die Anzahl an Schritten, die in die jeweiligen Richtungen der 26 Nachbarvoxel vollbracht werden kann, aufaddiert wird. Ein Schritt kann ausgeführt werden, wenn der Intensitätswert des erreichten Voxels nicht mehr als ein gegebener Parameter von dem Intensitätswert des Ausgangspunkt abweicht.
\newline
Der erste Schritt hat eine Länge von einem Voxel, der zweite von zwei Voxeln, der dritte von vier Voxeln... und so weiter. Die Schrittweite verdoppelt sich mit jedem weiteren Schritt bis hin zur Hälfte der Größe des gesamten Volumens. Hierbei kann ein Schritt trotzdem nur ausgeführt werden, wenn alle Voxel auf dem Weg das Kriterium erfüllen. Die Akkumulation alle Werte ergibt die geschätzte Größe der Struktur des Voxels. Dabei wird, um das Ergebnis weiterhin zu verbessern,  jeweils nur der kleinere Wert von zwei entgegengesetzten Richtungen in der Berechnung verwendet. 
\newline
Aus der geschätzten Größe und dem Intensitätswert wird ein zweidimensionales Histogramm erstellt. Abhängig von der euklidischen Distanz der Kästchen des Histogramms zu einem vom Benutzer gegebenen Punkt, werden die Farbwerte der einzelnen Voxel in einer Tabelle nachgeschaut.
\newline
Das Verfahren eignet sich gut, um relativ große Strukturen zu erkennen, jedoch ist es unklar ob das relativ schmale Ventrikelsystem erkannt werden würde.


Eine andere Idee Strukturen basierend auf räumlichen Informationen zu Segmentieren ist die Verwendung von Regiongrowing.
\newline
Beispielsweise wird im Paper von Huang \cite{huang2003rgvis} ein solches Regiongrowingverfahren vorgestellt.
\newline
Der Benutzer kann einen Punkt von Interesse im Volumen wählen, den sogenannten \textit{seed}. Es werden alle 26 Nachbarn des \textit{seeds} besucht und anhand einer Kostenfunktion, die den entsprechenden Wert des besuchten Voxels und des \textit{seed}voxels vergleicht, entschieden ob sie zu der Region dazugehören oder nicht. Sind sie Teil der Struktur werden auch ihre Nachbarn besucht und alle passenden Voxel zu der Region hinzugefügt. Diese Vorgang wiederholt sich so lange bis alle Voxel gefunden wurden, oder ein anderes internes Abbruchkriterium erfüllt wurde.
\newline
Es stehen dem Anwender 3 verschiedene Kostenfunktionen bereit. Die erste Funktion bezieht sich auf die Intensitätswerte der Voxel, die Zweite auf die Länge der jeweiligen Gradienten und bei der Dritten werden die Gewichte der Voxel verglichen, die vorher vom Benutzer definiert werden müssen. In einem Nachbearbeitungsschritt ist es anschließend noch möglich unpassende Elemente zu entfernen, wenn beispielsweise eine ganze weitere Struktur auch visualisiert wird, da sie über eine kleine Brücke von ein bis zwei Voxeln mit der eigentlich gesuchten Struktur verbunden ist.
\newline
Da das Regiongrowing sehr zeitaufwändig ist, kann der Anwender auswählen, dass er zunächst nur eine gewisse Teil der Region sich errechnen lässt.


Im Vergleich zu Huan \cite{huang2003rgvis} benutzt Chen  in seiner Arbeit \cite{chen2006sketch} nicht nur ein \textit{seed}basiertes Vorgehen, sondern fügt noch ein sketchbasiertes Verfahren davor ein.
\newline
Anfangs wählt der Anwender eine Reihe an Intensitätswerten im Histogramm, die für ihn interessant sind. Danach kann er direkt im Volumen eine Region von Interesse einzeichnen und markieren. Das Programm schneidet im Anschluss, alle Teile des Volumens, die außerhalb der gewählten Region liegen, weg. Jetzt kann der Nutzer wie im vorherig vorgestellten Verfahren seinen \textit{seed} setzen.
\newline
Dies erleichtert dem Benutzer die Anwendung, da er schneller zu seinem Punkt von Interesse gelangt ohne vorher durch diverse Querschnittbilder iterieren zu müssen. Des Weiteren ist es zeitsparend für den User, falls dieser sich nicht genau mit dem Datensatz und der zu Visualisierenden Region auskennt.


Correa und Ma zeigen in ihrer Arbeit \cite{correa2008size} hingegen einen Ansatz, der auf der relativen Größe der zu visualisierenden Features basiert.
\newline
Dazu benutzen sie den sogenannten \textit{scale-space}, welcher für das Volumen berechnet wird, um anschließend eine auf Größe basierende Transferfunktion anzuwenden. Diese mapt Farbe und Okklusion zu den entsprechenden Größen der Features des Volumens.
\newline
In einem weiteren Paper \cite{correa2009occlusion} beschreiben die beiden Forscher ein Verfahren, dass auf der Okklusion der Voxel basiert.
\newline
Dafür betrachten sie die Umgebung einzelner Voxel und berechnen abhängig davon, die Okklusion. Die Ergebnisse werden in einem zweidimensionalen Histogramm in Kombination mit den Intensitätswerten der Voxel gespeichert. Durch die Umgebungsokklusion der Voxel ist es leicht mit einer auf dem Histogramm basierenden Transferfunktion unterschiedliche Materialien mit gleichen Intensitätswerten zu unterscheiden.


Eine weitere Arbeit \cite{correa2009visibility} von Correa und Ma beschäftigt sich mit Transferfunktionen abhängig von der Sichtbarkeit einzelner Voxel.
\newline
Die Sichtbarkeit jedes Voxels wird abhängig vom Sichtpunkt auf das Volumen berechnet, indem die Opazität vom Standpunkt der Kamera bis hin zum Voxel akkumuliert wird. Anschließend wird ein Histogramm über die Sichtbarkeitswerte erstellt. Auf diesem kann der Benutzer eine Transferfunktion zur Bestimmung der optischen Visualisierung erstellen, bei der er ein direktes Feedback über die Darstellung erhält. Um das gewünschte Ergebnis zu erhalten, wäre jedoch ein sehr genaues Einstellen dieser Funktion von Nöten, was der User nur schwer umsetzten kann.
\newline
Aus diesem Grund wird eine Energiefunktion erstellt, die es zu minimieren gilt. Damit wird das Problem wie bei \cite{wu2007interactive} zu einem Optimierungsproblem, welches mithilfe von progressiver Suche gelöst werden kann. Der Anwender muss dafür lediglich ein Opazitätsfunktion angeben, die seine gewünschten Visualisierungsziele beschreibt. Hierbei kann er auch aus vorgefertigten Funktionen wählen.
\newline
Diese Histogramme wurde von Correa und Ma in einer erweiterten Arbeit \cite{correa2011visibility} nochmals verbessert. Sie führten multidimensionale Sichtbarkeitshistogramme ein, die beispielsweise auch die Gradientenlänge in Betracht ziehen. Des Weiteren stellen sie zwei Methoden zur Berechnung von Sichtpunkt unabhängigen Sichtbarkeitshistogrammen vor. Zum einen ein Omni-direktionales Sichtbarkeitshistogramm, bei dem die Sichtbarkeit von allen möglich Sichtpunkten berechnet wird. Und ein Radiales Sichtbarkeitshistogramm, bei dem radiale Strahlen verwendet werden. Dazu wird das kartesische in ein sphärisches Koordinatensystem umgerechnet.



\subsection{Machinelearning Verfahren}

Die Arbeit von Tzeng \cite{tzeng2005intelligent} benutzt Machinelearning um für den Nutzer interessante Strukturen darzustellen. Hierbei wird ein \textit{Neuronales Netz} und eine \textit{Support Vector Machine} benutzt.
\newline
Als Input für das Verfahren kann der Benutzer im Volumen mit zwei verschiedenen Farben Regionen anmalen und damit markieren. Mit der einen Farbe markiert der Nutzer die Stellen von Interesse, die er hervorgehoben haben möchte, mit der anderen Farbe Regionen, die ihn explizit nicht interessieren. Das Programm nimmt im Anschluss die Intensitätswerte, Länge der Gradienten und Intensitätswerte der Nachbarn aller markierter Voxel als Input um eine sinnvolle Segmentierung zu finden.
\newline
Das Ergebnis wird dem Anwender in Form einer farbigen Darstellung gezeigt, bei der er abhängig von der Farbe der Regionen erkennen kann wie ähnlich sie den mit der ersten Farbe angemalten Voxeln sind. Gefällt dem Benutzer das Ergebnis noch nicht, so kann er durch weiteres einfärben von Regionen das Ergebnis verbessern bis das gewünschte Resultat erreicht wird.


Soundararajan stellt ebenfalls ein Verfahren vor \cite{soundararajan2015learning}, bei dem der Anwender direkt im Volumen markieren kann, welche Gebiete für ihn von Interesse sind.
\newline
Dabei wird überwachtes maschinelles Lernen angewendet, um aus dieser Eingabe eine probabilistische Übertragungsfunktion abzuleiten. Dabei ist es wichtig, dass das ausgewählte Machinelearningverfahren eine probabilistische Klassifikation erlaubt. Des Weiteren darf es nicht nur zwischen zwei verschiedenen Klassen unterscheiden können, sondern multiple Klassen unterstützen.
\newline
In dem Paper wird das Verfahren mit fünf verschiedenen Machinelearningverfahren getestet und erklärt wie weit mit diesen das gegebene Verfahren umsetzbar ist. Es wurden \textit{Gaussian Naive Bayes}, \textit{k Nearest Neighbor}, \textit{Support Vector Machines}, \textit{Random Forests} und \textit{Neural Networks} getestet.



\subsection{Bildbasierte Verfahren}

Eine weitere Art Transferfunktionen anzuwenden, sind Verfahren, die auf ?einem Bild? basieren. Hier hat der Benutzer die Möglichkeit, mit dem Programm zu interagieren. Dies ist für einen unerfahrenen User intuitiver und er kann durch ausprobieren ein gewünschtes Ergebnis erzielen.
\newline
Fang stellt in seinem Paper \cite{fang1998image} ein Verfahren vor, bei dem die  Transferfunktion eine Abfolge von verschieden 3D Bildverabteitungsverfahren ist, deren Parameter vom Benutzer angepasst werden können.
\newline
Es gibt auch Methoden, bei denen ein Hilfswerkzeug zum Einsatz kommt. Zum Beispiel kann der Benutzer im Paper von Reitinger: \cite{reitinger2004user} sich gezielt Bereiche des Volumens hervorheben lassen, indem er sie mit einem Stift auswählt. Hierbei wird die Intensität des ausgewählten Punktes als auch der räumliche Abstand zum Stift in Betracht gezogen.
\newline
Wu und Qu stellen in ihrer Arbeit \cite{wu2007interactive} ein intuitives Verfahren zum verändern von Features von Transferfunktionen vor.
\newline
Der Benutzer lädt zwei verschiedene \textit{direct volume rendered images(DVRIs)} in das Programm. Hierbei wird ihm die jeweilige Visualisierung und Transferfunktion angezeigt. Der User kann entscheiden ob er gewisse Features der beiden DVRIs zu einem verschmelzen, aus beiden mischen oder einzelne löschen möchte. Die Zusammenführung geschieht im Anschluss mithilfe einer Energiefunktion, die die Ähnlichkeit zweier Bilder beschreibt. Das Zusammenführen wird somit zu einem Optimierungsproblem undzwar dem minimieren der Energiefunktion. Dieses Problem kann mithilfe eines stochastischen Suchalgorithmus gelöst werden. Der Anwender bekommt am eine Visualisierung mit allen gewünschten Features.



\subsection{Clusteringbasierte Verfahren}

Sereda baut seine Arbeit \cite{sereda2006visualization} auf den von Serlie \cite{serlie2003computed} vorgestellten LH-Histogrammen auf und zeigt wie es mithilfe von ihnen möglich ist Objekte zu klassifizieren.
\newline
Die Berechnung eines LH-Histogramms ist eine Methode zur Erkennung von Kanten, unter der Verwendung von Low- und High-Werten. Dabei werden die Voxel in zwei verschiedenen Kategorien eingeteilt. Es gibt Voxel, die  innerhalb eines Materials liegen und welche, die  an der Grenze zweier Materialien liegen. Ist ein Voxel innerhalb, so sind seine LH-Werte gleich. Grenzvoxel hingegen haben unterschiedliche Low- und High-Werte, wobei diese die Intensitätswerte der beiden Materialien, zwischen denen die Grenze verläuft, beschreiben. 
\newline
Bei der Berechnung des Histogramms wird als erstes getestet, ob der betrachtete Voxel an einer Grenze liegt. Ein Punkt liegt innerhalb eines Materials, wenn  die Länge des Gradienten kleiner als ein gewisses epsilon (bei MRT-Daten) oder gleich null(bei CT-Daten ist). In diesem Fall wären die Low- und High-Werte der Intensitätswert des Voxels. Ist dies jedoch nicht der Fall, wird in Richtung(für die High-Werte) und entgegengesetzter Richtung(für die Low-Werte) des Gradienten schrittweise integriert. Die Integration stoppt sobald ein Material gefunden wurde. Dies wird für jeden Punkt im Volumen berechnet und danach aus allen LH-Werten ein Histogramm erstellt.
\newline 
Zur Visualisierung benutzt Sereda eine dreidimensionale Transferfunktion. Diese nimmt die beiden LH-Werte als auch die Gradientenlänge, aus dem Grund, dass vor allem Voxel nah an der Grenze interessant sind und diese dadurch hervorgehoben werden, als Parameter entgegen.
\newline
Anschließend verwenden die Forscher Regiongrowing um Strukturen noch deutlicher erkennen zu können. Dabei basiert die Kostenfunktion auf dem LH-Histogramm. Dies beschreiben sie als deutlich besser als Kostenfunktionen, die auf dem Intensitätswert und der Gradientenlänge basieren, da Kanten trotz Überlappungen besser erkannt werden können.
\newline
In einer späteren Arbeit \cite{sereda2006automating} stellt Sereda ein hierarchisches Clusteringverfahren vor. Hierbei werden in einer Menge von Clustern immer die zwei verschmolzen, die sich bei dem ausgewählten Vergleichsverfahren am ähnlichsten sind. Es wird eine Kombination aus zwei solcher Vergleichsverfahren vorgestellt. Zum einen wird die räumliche Nähe in Betracht gezogen, bei der gezählt wird, wie viele direkte Nachbarn zwei Cluster besitzen. Zum anderen wird die Nähe im LH-Raum untersucht. Als Startcluster dienen hierbei die Kästchen des LH-Histogramms. Die einzelnen Cluster bekommen für die Visualisierung am Ende eine zufälligen Farbwert zugewiesen. 


Das Paper von Binh P. Nguyen \cite{nguyen2012clustering} stellt ebenfalls ein clusteringbasiertes Verfahren vor.
\newline
Zunächst wird in einem Vorverarbeitungsschritt die Gradienten des Volumens berechnet. Hierzu wurde Hong's Methode \cite{hong2003method} verwendet. Im Anschluss daran wird anhand der Gradienten die LH-Werte mithilfe von Heuns Methode, ein modifizierte Euler Methode, ermittelt.Hierbei wird des Weiteren eine Gewichtung abhängig von der zurückgelegten Strecke bei der Interpolation für den Low- beziehungsweise. High-Wert errechnet. Aus den LH-Werten und deren Gewichten wird anschließend ein LH-Histogramm erzeugt.
\newline
Dem Benutzter steht dann ein zwei stufiges und ein drei stufiges Clusteringverfahren zur Auswahl, wobei die ersten beiden Clusteringschritte die Selben sind. 
Im ersten Clusteringschritt wird im LH-Raum mithilfe von \textit{Meanshiftclustering} geclustert. Es wird für jeden LH-Wert alle Werte gefunden, die in einem Kreis mit einem Radius von 7\% - 9\%  des maximalen LH-Wertes um den ursprünglichen Punkt liegen. Anschließend wird der neue durchschnittliche Mittelpunkt von allen Punkten im Cluster ermittelt. Der Vorgang wiederholt sich der Mittelpunkt zwischen zwei Iterationen nur minimal ändert. Der komplette Vorgang wird für jeden Punkt im LH-Histogramm wiederholt und in Folge werden Cluster, deren Mittelpunkt nah beieinander liegen zu einem Cluster verschmolzen.
\newline
Der zweite Clusteringschritt wird auf die Cluster des ersten Schrittes angewendet. Hierbei wird auch \textit{Meanschiftclustering} verwendet. Diesmal wird jedoch räumlich, also abhängig von der Position im Volumen, geclustert. Des Weiteren werden die Parameter für den Suchradius und Distanz zweier Mittelpunkte damit sie verschmolzen werden angepasst.
\newline
Das Ergebnis der ersten zwei Schritte sind Cluster, bei denen alle Voxel ähnliche LH-Werte haben, als auch räumlich nah beieinander liegen.
\newline
Im optionalen dritten und letzten Clusteringschritt wird hierarchisch geclustert. Hierbei wird für jeden Cluster die paarweise Nähe zu jedem anderen Cluster errechnet. Anschließend werden hierarchisch immer die zwei Cluster, die sich am nächsten sind, zu einem verschmolzen, solange bis nur noch ein Cluster existiert.  Hierbei speichert das Programm jeweils welche Cluster wann miteinander verschmolzen wurden. Der Benutzer kann im Anschluss entscheiden wie viel Cluster er haben möchte. Abhängig davon, wird das hierarchische Clustern umgekehrt und die Cluster werden wieder getrennt, bis die gewünschte Anzahl an Clustern erreicht ist.


\subsection{Wahl des Verfahrens}


Bei der Wahl des in dieser Bachelorarbeit verwendeten Verfahrens, könnten viele der gerade vorgestellten Herangehensweisen zu einer erfolgreichen Visualisierung des Ventrikelsystems führen. Andere scheiden jedoch schon prinzipiell aus.
\newline
Beispielsweise eignen sich eindimensionale und zweidimensionale Transferfunktionen schlecht für diese Aufgabe. Sie sind von ihrer Herangehensweise zu direkt und leiden oft an Überlappungen. Auch das genaue Abgrenzen von kleineren Strukturen, deren Intensitätswerte womöglich mehrfach im Volumen vorkommen ist damit schwer bis gar nicht möglich.
\newline 
Ein Verfahren wie von Lan \cite{lan2017improving} vorgeschlagen eignet sich schon besser für diese Aufgabe. Jedoch ist, wie schon erwähnt wurde, der Aufwand der Implementierung für den Rahmen dieser Bachelorarbeit zu groß.
\newline
Weiterhin wurden verschiedene Transferfunktionen vorgestellt, die auf den räumlichen Informationen der anzuzeigenden Regionen basieren. Die Implementation eines solchen Verfahrens würde vermutlich ebenfalls zu einer erfolgreichen Darstellung des Ventrikelsystems führen. Jedoch benötigt der Anwender für all diese Herangehensweisen nicht nur die Information wie das Ventrikelsystem aussieht, sondern auch wo es im Volumen zu finden ist. Folglich funktionieren diese Verfahren zwar, sind aber wenig intuitiv und benötigen ein gewisses Fachwissen seitens des Nutzers. Darum wurde sich gegen einen Räumlichbasiertes Vorgehen entschieden.
\newline
Aus diesen Gründen, wurde sich in dieser Arbeit auf die Implementierung des clusteringbasierten Verfahren von Nguyen \cite{nguyen2012clustering} festgelegt. Dieses eignet sich mit der Kantenerkennung gut zum Segmentieren von gezielten Strukturen.























































